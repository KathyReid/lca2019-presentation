# INTRODUCTION


welcome in Maori



thank you to the volunteers, AV?

mention Duncan MacNeil coined the term - photo of him from LCA2018

# OVERVIEW

## Voice within the context of evolving user interfaces

Not so long ago - a couple of decades perhaps, speaking with a computer was relegated to the realms of science fiction. We saw cars that could talk;

IMAGE: KITT in Knight Rider

computers that could talk - "hello computer" _in Scottish accent_

IMAGE: Star Trek computer

and even holograms that could talk;

IMAGE: Time Trax

Just like many of the technology showcased in these series - Knight Rider, Star Trek, Time Trax, voice user interfaces are quickly moving from science fiction to science fact. Advances in processor speed, compute power, machine learning and neural networks are quickly making voice user interfaces a reality.

However, commercial, proprietary solutions have led the way here - Apple, with Siri, Amazon with Alexa, Microsoft with Cortana, Samsung with Bixy. There are many reasons for this - which I'll discuss throughout the presentation, but like many of you, I'd really like to see some open source solutions available which rival the maturity and feature completeness of the proprietary solutions.




## Introduction to the voice stack

_How many people in the audience are familiar with some type of speech recognition or text to speech service? That's great!_

Just like there are **stacks** of software for things like web servers or databases, or application servers, voice stacks need certain layers as well. I'm going to spend a few minutes providing a brief overview of a typical voice stack, primarily to provide some context for the rest of the presentation.



# WAKE WORD


## Phonemes


# SKILLS

## General challenges with Skills



## Fallback Skills
Confidence of which fallback is activating



## Voice user interaction

Haber's classification of contexts




image credits
